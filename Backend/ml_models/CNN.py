# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18LtCO4Hth20dLIkY4dvwFSj-uzeXDHQn
"""


import ssl

ssl._create_default_https_context = ssl._create_unverified_context
import urllib  # For fetching data from Web URLs

import cv2  # For image processing
import keras
import numpy as np
import pandas as pd
import tensorflow as tf
from keras import Model
from keras.layers import GlobalMaxPooling2D
from matplotlib import pyplot as plt  # for viewing images and plots
from sklearn.model_selection import train_test_split  # For splitting of dataset
from sklearn.preprocessing import LabelEncoder  # For encoding categorical variables
from tensorflow.keras.applications.resnet50 import (
    ResNet50,
    decode_predictions,
    preprocess_input,
)

# from keras.preprocessing import image
from tensorflow.keras.preprocessing import image

# So that Matplotlib plots don't open in separate windows outside the notebook


# All tensorflow utilities for creating, training and working with a CNN
# from tensorflow.keras.utils import to_categorical
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization
# from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
# from tensorflow.keras.losses import categorical_crossentropy
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import ModelCheckpoint
# from keras.preprocessing.image import load_img

tf.__version__


# from IPython.core.interactiveshell import InteractiveShell
# InteractiveShell.ast_node_interactivity = 'all'


ordersExport = pd.read_csv("datasets/orders_export.csv")
productsExport = pd.read_csv("datasets/products_export_1.csv")


productsExport = productsExport[productsExport["Tags"].isnull() == False]

productsExport = productsExport[productsExport["Published"] == True]

productsExport = productsExport[["Title", "Image Src", "Variant SKU"]]
productsExport = productsExport.rename(columns={"Image Src": "image"})

productsExport = productsExport.iloc[0:163]

productsExport = productsExport.reset_index(drop=True)


def show_image_from_url(image_url):

    """
    Fetches image online from the image_url and plots it as it is using matplotlib's pyplot's image show
    """

    response = urllib.request.urlopen(image_url)
    image = np.asarray(bytearray(response.read()), dtype="uint8")
    image_bgr = cv2.imdecode(image, cv2.IMREAD_COLOR)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    #     print(response)
    return image_rgb


def load_image(img, resized_fac=0.1):
    #     img     = cv2.imread(show_image_from_url(img))
    img = show_image_from_url(img)
    w, h, _ = img.shape
    resized = cv2.resize(
        img, (int(h * resized_fac), int(w * resized_fac)), interpolation=cv2.INTER_AREA
    )
    return resized


# Input Shape
img_width, img_height, _ = 1800, 1200, 3  # load_image(df.iloc[0].image).shape

# Pre-Trained Model
base_model = ResNet50(
    weights="imagenet", include_top=False, input_shape=(img_width, img_height, 3)
)
base_model.trainable = False

# Add Layer Embedding
model = keras.Sequential([base_model, GlobalMaxPooling2D()])

model.summary()


def get_embedding(model, img_name):
    print(img_name)
    # Reshape
    #     img = image.load_img(img_name, target_size=(img_width, img_height))
    img = show_image_from_url(img_name)
    #     print(img)
    # img to Array
    x = image.img_to_array(img)
    #     print(x)
    # Expand Dim (1, w, h)
    x = np.expand_dims(x, axis=0)
    # Pre process Input
    x = preprocess_input(x)
    return model.predict(x).reshape(-1)


emb = get_embedding(model, productsExport.iloc[1].image)

img_array = load_image(productsExport.iloc[2].image)
plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))


# import swifter

# Parallel apply
map_embeddings = productsExport["image"].apply(lambda img: get_embedding(model, img))
df_embs = map_embeddings.apply(pd.Series)

print(df_embs.shape)
df_embs.head()


df_embs = df_embs.reset_index(drop=True)

from sklearn.metrics.pairwise import pairwise_distances

# Calculate Distance Matrix
cosine_sim = 1 - pairwise_distances(df_embs, metric="cosine")

sku = productsExport["Variant SKU"]
sku_mappings = sku.to_dict()

indices = pd.Series(range(len(productsExport)), index=productsExport.index)


# Function that get movie recommendations based on the cosine similarity score of movie genres
def get_recommender(idx, productsExport, top_n=5):
    sim_idx = indices[idx]
    sim_scores = list(enumerate(cosine_sim[sim_idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1 : top_n + 1]
    idx_rec = [i[0] for i in sim_scores]
    idx_sim = [i[1] for i in sim_scores]

    return sku.iloc[idx_rec], indices.iloc[idx_rec], idx_sim


recommendations = {}
for idx in range(0, 134):
    recommendation, _, _ = get_recommender(idx, productsExport, top_n=5)
    recommendation = recommendation.to_dict()
    recommendation_sku = {sku_mappings[idx]: [v for k, v in recommendation.items()]}
    recommendations.update(recommendation_sku)


def plot_figures(figures, nrows=1, ncols=1, figsize=(8, 8)):

    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)
    for ind, title in enumerate(figures):
        axeslist.ravel()[ind].imshow(cv2.cvtColor(figures[title], cv2.COLOR_BGR2RGB))
        axeslist.ravel()[ind].set_title(title)
        axeslist.ravel()[ind].set_axis_off()
    plt.tight_layout()


# Idx Item to Recommender
idx_ref = 85

# Recommendations
sku, idx_rec, idx_sim = get_recommender(idx_ref, productsExport, top_n=6)

# Plot
# ===================
plt.imshow(
    cv2.cvtColor(load_image(productsExport.iloc[idx_ref].image), cv2.COLOR_BGR2RGB)
)

# generation of a dictionary of (title, images)
figures = {
    "im" + str(i): load_image(row.image)
    for i, row in productsExport.loc[idx_rec].iterrows()
}
# plot of the images in a figure, with 2 rows and 3 columns
plot_figures(figures, 2, 3)

import pickle

pickle_out = open("model.pkl", "wb")
pickle.dump(recommendations, pickle_out)
pickle_out.close()
